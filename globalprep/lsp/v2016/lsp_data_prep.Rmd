---
title: 'OHI: Lasting Special Places '
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohiprep/src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = FALSE, message = FALSE, warning = FALSE)

library(foreign)
library(sp)
library(rgdal)
# library(raster)
# library(maptools)
library(readr)

source('~/github/ohiprep/src/R/common.R')

goal     <- 'globalprep/lsp'
scenario <- 'v2016'
dir_anx       <- file.path(dir_M, 'git-annex') 
dir_goal      <- file.path('~/github/ohiprep', goal, scenario)
dir_goal_anx  <- file.path(dir_anx,            goal, scenario)
dir_data_wdpa <- file.path(dir_anx, '_raw_data/wdpa_mpa', 'd2016') 

### set up provenance tracking for this script:
# source(file.path('~/github/ohibc', 'src/R/prov.R'))          


source(file.path(dir_git, scenario, 'lsp_fxn.R'))
if(!file.exists(file.path(dir_git, 'README.md'))) {
  warning(sprintf('No README detected in %s', dir_git))
}
if(!file.exists(file.path(dir_git, scenario, 'README.md'))) {
  warning(sprintf('No README detected in %s', file.path(dir_git, scenario)))
}

```

``` {r wdpa_shapefile1}

shp_raw     <- file.path(dir_data_wdpa, 
                         'WDPA_May2016-shapefile',
                         'WDPA_May2016-shapefile-polygons')
shp_reorder <- file.path(dir_data_wdpa, 
                         'WDPA_May2016_shp_ordered')
shp_xformed <- file.path(dir_data_wdpa, 
                         'WDPA_May2016_shp_xformed')

### Filter criteria:
### * MANG_PLAN does not include "Non-MPA Programmatic"
### * STATUS is "Designated" only (NOT "Proposed", "Adopted", "Inscribed", or "Not Reported")
###   * see WDPA Manual: field name STATUS:
###     "Is recognized or dedicated through legal means. Implies specific binding commitment
###      to conservation in the long term. Applicable to government and non-government sources."
###   * "Adopted" and "Inscribed" are World Heritage or Barcelona Convention sites;
###     protected by other means in addition to these.

if(!file.exists(paste0(shp_xformed, '.shp'))) {
  message('No shp found for filtered/reordered/transformed WDPA database')
  if(!file.exists(paste0(shp_reorder, '.shp'))) {
    message('No shp found for filtered/reordered WDPA database')
    ### Read in the raw shapefile (3.2 GB)
    message('Reading in raw shapefile: \n  ', shp_raw)
    ptm <- proc.time()
    wdpa_poly <- readOGR(dsn   = dirname(shp_raw),
                         layer = basename(shp_raw))
    message('elapsed: ', (proc.time() - ptm)[3])
    
    ### filter polygons
    wdpa_poly <- wdpa_poly[wdpa_poly@data$STATUS == 'Designated', ]
    wdpa_poly <- wdpa_poly[!str_detect(tolower(wdpa_poly@data$MANG_PLAN), 'non-mpa program'), ]
    
    ### reorder polygons (oldest last) and save shapefile
    reorder_vec <- order(wdpa_poly@data$STATUS_YR, decreasing = TRUE)
    wdpa_poly1 <- wdpa_poly[reorder_vec, ]
    
    message('Writing filtered/reordered WDPA polygons to: \n  ', shp_reorder)
    ptm <- proc.time()
    writeOGR(wdpa_poly1, 
             dsn    = dirname(shp_reorder),
             layer  = basename(shp_reorder),
             driver = 'ESRI Shapefile')
    message('elapsed: ', (proc.time() - ptm)[3])
    ### lots of warnings similar to:
    ###   "Warning 1: Value 555593627 of field WDPAID of feature 507 not /
    ###    successfully written. Possibly due to too larger number with /
    ###    respect to field width"
    ### warning ignored: WDPAID field not used in analysis
    
    ### clean up the memory by removing this huge-ass object
    rm('wdpa_poly')
 
  } else {
    ### reordered shapefile exists; read it in
    message('Reading in filtered/re-ordered shapefile: \n  ', shp_reorder)
    ptm <- proc.time()
    wdpa_poly1 <- readOGR(dsn   = dirname(shp_reorder),
                          layer = basename(shp_reorder))
    message('elapsed: ', (proc.time() - ptm)[3])
  }
  
  message('Spatial transforming WDPA polygons to Mollweide')
  ### spatial transform the polygon into Mollweide CRS
  crs_mol <- CRS('+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')
  ptm <- proc.time()
  wdpa_poly2 <- spTransform(wdpa_poly1, crs_mol)
  message('elapsed: ', (proc.time() - ptm)[3])
  ### elapsed: 485.793s on Mazu

  message('Writing filtered/reorderedtransformed WDPA polygons to: \n  ', shp_xformed)
  ptm <- proc.time()
  writeOGR(wdpa_poly2, 
           dsn    = dirname(shp_xformed),
           layer  = basename(shp_xformed),
           driver = 'ESRI Shapefile')
  message('elapsed: ', (proc.time() - ptm)[3])
  ### elapsed: 1445.093 on Mazu

  ### clean up the memory by removing these huge-ass objects
  rm(c('wdpa_poly1', 'wdpa_poly2'))

} else {
  ### transformed shapefile exists
  message('Transformed WDPA shapefile exists at \n  ', shp_xformed)
  message('Go inspect it to make sure it looks good!')
}

```


``` {r check_data_attributes_for_probs, eval = FALSE}
### to check existing SPDF for unfiltered polygons:
wdpa_df <- foreign::read.dbf(paste0(shp_xformed, '.dbf'))

names(wdpa_df)
#  WDPAID | WDPA_PID | PA_DEF | NAME | ORIG_NAME | DESIG | DESIG_ENG | DESIG_TYPE | IUCN_CAT
#  INT_CRIT | MARINE | REP_M_AREA | GIS_M_AREA | REP_AREA | GIS_AREA | NO_TAKE | NO_TK_AREA | STATUS
#  STATUS_YR | GOV_TYPE | OWN_TYPE | MANG_AUTH | MANG_PLAN | VERIF | METADATAID | SUB_LOC | PARENT_ISO
#  ISO3
nonmpa_check <- wdpa_df %>%
  filter(ISO3 == 'USA') %>% ### USA non-programmatic management plans were a problem in 2015
  select(MANG_PLAN) %>%
  distinct()
### if there are any non-MPA programmatic species management plans in here, filter 'em

newstatus_check <- wdpa_df %>%
  filter(STATUS %in% c("Adopted", "Inscribed"))
doubled_check <- wdpa_df %>%
  filter(str_detect(tolower(NAME), "yosemite|yellowst|chitwan|tikal|nahanni"))
### looks like most of those parks are covered under other rubrics as well

```


``` {r rasterize_wdpa_mollweide}

### Check base raster:
dir_rast <- file.path(dir_anx, 'globalprep/spatial/v2015/data/rgn_raster_500m')
fn_rast_base <- file.path(dir_rast, 'rgn_offshore3nm_mol_500mcell.tif')
rast_base    <- raster::raster(fn_rast_base)
# plot(rast_base)

### setup gdal_rasterize based on base raster and shp_xformed
out_tif <- file.path(dir_goal_anx, 'int/wdpa_may2016.tif')

te <- rast_base@extent
base_te <- c(te@xmin, te@ymin, te@xmax, te@ymax)
base_tr <- raster::res(rast_base)

in_shp <- paste0(shp_xformed, '.shp')

out_tif_tmp <- out_tif %>%
  str_replace('.tif', '_tmp.tif')
if(!file.exists(out_tif_tmp))
  raster::writeRaster(rast_base, out_tif_tmp)
### need a file there for gdalUtils::gdal_rasterize to do its work

message('Rasterizing:\n  ', in_shp, '\nto temp tif: \n  ', out_tif_tmp)
rast_tmp <- gdalUtils::gdal_rasterize(
  src_datasource = path.expand(in_shp),
  dst_filename   = path.expand(out_tif_tmp),
  a = 'STATUS', # attribute to burn
  a_nodata = NA,
  # at = TRUE,
  te = base_te,
  tr = base_tr,
  output_Raster = TRUE)

### rewrite for compression and unlink the temp raster
message('Compressing: \n  ', out_tif_tmp, '\nto: \n  ', out_tif)
raster::writeRaster(rast_tmp, out_tif, overwrite = TRUE)
unlink(out_tif_tmp)

```

[REFERENCE RMD FILE: https://cdn.rawgit.com/OHI-Science/ohiprep/master/globalprep/prs_oa/v2016/oa_dataprep.html]

#Summary
[general description: What data are being generated? Why (what project, etc.)? Upstream/downstream processing information that might be helpful?  Other information?]

#Updates from previous assessment
[Any significant changes in methods from previous analyses?]

***

#Data Source
**Reference**: IUCN and UNEP-WCMC (2016), The World Database on Protected Areas (WDPA) [On-line], May 2016. Cambridge, UK: UNEP-WCMC. Available at: www.protectedplanet.net.

**Downloaded**: June 7, 2016

**Description**:  Shapefile of World Database on Protected Areas

**Time range**: [e.g., 1880-1899, monthly data provided for each year] 

**Format**:  Shapefile

***
  
#Methods
[R code used to generate the data. Or, alternatively, description of the code/data files used to generate the data.]

***

#Citation information  
[citation information: include if these data will have their own specific citation.]